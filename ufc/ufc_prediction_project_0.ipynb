{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFC 경기 승패 예측 (모든 특성 사용 최종본)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('UFC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 전처리 및 특성 공학"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [전처리] 불필요 컬럼 제거 및 결측치 처리\n",
    "df.dropna(subset=['winner', 'r_dob', 'b_dob', 'r_stance', 'b_stance', 'r_height', 'b_height'], inplace=True)\n",
    "df['r_reach'].fillna(df['r_height'], inplace=True)\n",
    "df['b_reach'].fillna(df['b_height'], inplace=True)\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "# [특성 공학] 타겟 변수 및 파생 변수 생성\n",
    "df['winner_is_red'] = (df['winner'] == df['r_name']).astype(int)\n",
    "df['r_dob'] = pd.to_datetime(df['r_dob'])\n",
    "df['b_dob'] = pd.to_datetime(df['b_dob'])\n",
    "df['r_age'] = (pd.to_datetime('today') - df['r_dob']).dt.days / 365.25\n",
    "df['b_age'] = (pd.to_datetime('today') - df['b_dob']).dt.days / 365.25\n",
    "df.drop(['r_dob', 'b_dob'], axis=1, inplace=True)\n",
    "\n",
    "# 차이 특성\n",
    "df['age_diff'] = df['r_age'] - df['b_age']\n",
    "df['height_diff'] = df['r_height'] - df['b_height']\n",
    "df['reach_diff'] = df['r_reach'] - df['b_reach']\n",
    "df['wins_diff'] = df['r_wins'] - df['b_wins']\n",
    "df['losses_diff'] = df['r_losses'] - df['b_losses']\n",
    "df['splm_diff'] = df['r_splm'] - df['b_splm']\n",
    "df['str_acc_diff'] = df['r_str_acc'] - df['b_str_acc']\n",
    "df['sapm_diff'] = df['r_sapm'] - df['b_sapm']\n",
    "df['str_def_diff'] = df['r_str_def'] - df['b_str_def']\n",
    "df['td_avg_diff'] = df['r_td_avg'] - df['b_td_avg']\n",
    "df['td_acc_diff'] = df['r_td_avg_acc'] - df['b_td_avg_acc']\n",
    "df['td_def_diff'] = df['r_td_def'] - df['b_td_def']\n",
    "df['sub_avg_diff'] = df['r_sub_avg'] - df['b_sub_avg']\n",
    "\n",
    "# 비율 및 복합 특성\n",
    "# ratio features (0~1 scaled)\n",
    "df['sig_str_ratio'] = df['r_splm'] / (df['r_splm'] + df['b_splm'] + 1e-6)\n",
    "df['td_ratio'] = df['r_td_avg'] / (df['r_td_avg'] + df['b_td_avg'] + 1e-6)\n",
    "df['str_acc_ratio'] = df['r_str_acc'] / (df['r_str_acc'] + df['b_str_acc'] + 1e-6)\n",
    "df['td_acc_ratio'] = df['r_td_avg_acc'] / (df['r_td_avg_acc'] + df['b_td_avg_acc'] + 1e-6)\n",
    "\n",
    "# win ratio features\n",
    "df['r_win_ratio'] = df['r_wins'] / (df['r_wins'] + df['r_losses'] + 1e-6)\n",
    "df['b_win_ratio'] = df['b_wins'] / (df['b_wins'] + df['b_losses'] + 1e-6)\n",
    "df['win_ratio_diff'] = df['r_win_ratio'] - df['b_win_ratio']\n",
    "\n",
    "# ---------- 추가 파생 특성 ----------\n",
    "# BMI\n",
    "df['r_bmi'] = df['r_weight'] / ((df['r_height'] / 100) ** 2 + 1e-6)\n",
    "df['b_bmi'] = df['b_weight'] / ((df['b_height'] / 100) ** 2 + 1e-6)\n",
    "df['bmi_diff'] = df['r_bmi'] - df['b_bmi']\n",
    "\n",
    "# Reach / Height 비율\n",
    "df['r_reach_ht_ratio'] = df['r_reach'] / (df['r_height'] + 1e-6)\n",
    "df['b_reach_ht_ratio'] = df['b_reach'] / (df['b_height'] + 1e-6)\n",
    "df['reach_ht_ratio_diff'] = df['r_reach_ht_ratio'] - df['b_reach_ht_ratio']\n",
    "\n",
    "\n",
    "# 총 경기 수\n",
    "df['r_total_fights'] = df['r_wins'] + df['r_losses']\n",
    "df['b_total_fights'] = df['b_wins'] + df['b_losses']\n",
    "df['total_fights_diff'] = df['r_total_fights'] - df['b_total_fights']\n",
    "\n",
    "# ---------- 추가 파생 특성 v3 ----------\n",
    "# 1) 공격 점수: Striking + Grappling 효율 합\n",
    "df['r_offense_score'] = df['r_str_eff'] + df['r_grap_eff'] if 'r_str_eff' in df.columns else \\\n",
    "                        (df['r_splm'] * df['r_str_acc']) + (df['r_td_avg'] * df['r_td_avg_acc'])\n",
    "df['b_offense_score'] = df['b_str_eff'] + df['b_grap_eff'] if 'b_str_eff' in df.columns else \\\n",
    "                        (df['b_splm'] * df['b_str_acc']) + (df['b_td_avg'] * df['b_td_avg_acc'])\n",
    "df['offense_score_diff'] = df['r_offense_score'] - df['b_offense_score']\n",
    "\n",
    "# 2) 방어 점수: 타격·테이크다운 방어율 평균\n",
    "df['r_defense_score'] = (df['r_str_def'] + df['r_td_def']) / 2\n",
    "df['b_defense_score'] = (df['b_str_def'] + df['b_td_def']) / 2\n",
    "df['defense_score_diff'] = df['r_defense_score'] - df['b_defense_score']\n",
    "\n",
    "# 3) 순공격 이득(Net Advantage) = 공격 diff + 방어 diff\n",
    "df['net_advantage'] = df['offense_score_diff'] + df['defense_score_diff']\n",
    "\n",
    "# 4) 상호작용 특성: 레드의 공격 vs 블루의 방어, 블루의 공격 vs 레드의 방어\n",
    "df['str_vs_def_diff'] = (df['r_str_acc'] * df['b_str_def']) - (df['b_str_acc'] * df['r_str_def'])\n",
    "\n",
    "# 5) 공격/방어 스코어 비율 차이\n",
    "df['off_def_ratio_diff'] = (df['r_offense_score'] / (df['r_defense_score'] + 1e-6)) - \\\n",
    "                           (df['b_offense_score'] / (df['b_defense_score'] + 1e-6))\n",
    "\n",
    "# 스탠스 조합 (범주형)\n",
    "df['stance_comb'] = df['r_stance'].astype(str) + '_' + df['b_stance'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델링 준비 (모든 특성 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용된 총 특성 개수: 75\n"
     ]
    }
   ],
   "source": [
    "# 모든 생성된 특성 정의\n",
    "numerical_features = [col for col in df.columns if df[col].dtype != 'object' and col not in ['winner_is_red', 'winner']]\n",
    "categorical_features = ['r_stance', 'b_stance', 'stance_comb']\n",
    "\n",
    "# 최종 데이터셋 정의 및 분할\n",
    "X = df[numerical_features + categorical_features]\n",
    "y = df['winner_is_red']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f'사용된 총 특성 개수: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. 모델 테스트 (LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted  Probability  Correct\n",
      "7346       1          1     0.547887     True\n",
      "5070       1          1     0.774081     True\n",
      "7802       1          1     0.825310     True\n",
      "5532       0          0     0.249534     True\n",
      "5941       1          0     0.309420    False\n",
      "...      ...        ...          ...      ...\n",
      "6837       1          1     0.776406     True\n",
      "5848       0          0     0.393903     True\n",
      "7964       1          1     0.661564     True\n",
      "7628       1          1     0.931696     True\n",
      "6973       1          1     0.901048     True\n",
      "\n",
      "[1572 rows x 4 columns]\n",
      "LogisticRegression Score:  0.710559796437659\n"
     ]
    }
   ],
   "source": [
    "# 수치형 전처리: 결측치 평균 대체 + 정규화\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 범주형 전처리: 결측치 최빈값 대체 + 원핫 인코딩\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 전처리 통합\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# 모델 정의 (클래스 불균형 고려)\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "# 파이프라인 구성\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', logreg)\n",
    "])\n",
    "\n",
    "# 모델 학습\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# 예측 확률 추출\n",
    "y_proba = model_pipeline.predict_proba(X_test)[:, 1]  # 클래스 1(레드 승)의 확률만 추출\n",
    "\n",
    "# 확률 포함 결과 DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Probability': y_proba,\n",
    "    'Correct': y_test == y_pred\n",
    "})\n",
    "\n",
    "print(results_df)\n",
    "print('LogisticRegression Score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. 모델 테스트 (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted  Probability  Correct\n",
      "7346       1          1         0.65     True\n",
      "5070       1          1         0.79     True\n",
      "7802       1          1         0.67     True\n",
      "5532       0          0         0.47     True\n",
      "5941       1          1         0.79     True\n",
      "...      ...        ...          ...      ...\n",
      "6837       1          1         0.78     True\n",
      "5848       0          0         0.34     True\n",
      "7964       1          1         0.84     True\n",
      "7628       1          1         0.77     True\n",
      "6973       1          1         0.94     True\n",
      "\n",
      "[1572 rows x 4 columns]\n",
      "RandomForest Score:  0.7315521628498728\n"
     ]
    }
   ],
   "source": [
    "# 전처리기 정의\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)])\n",
    "\n",
    "# 클래스 불균형 처리 가중치\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "\n",
    "# 기본 모델 정의\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# 전처리 + 모델을 하나의 파이프라인으로 구성\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# 모델 학습\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# 예측 확률 추출\n",
    "y_proba = model_pipeline.predict_proba(X_test)[:, 1]  # 클래스 1(레드 승)의 확률만 추출\n",
    "\n",
    "# 확률 포함 결과 DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Probability': y_proba,\n",
    "    'Correct': y_test == y_pred\n",
    "})\n",
    "\n",
    "print(results_df)\n",
    "print('RandomForest Score: ',model_pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3. 모델 테스트 (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted  Probability  Correct\n",
      "7346       1          1     0.584937     True\n",
      "5070       1          1     0.868597     True\n",
      "7802       1          1     0.986028     True\n",
      "5532       0          0     0.431876     True\n",
      "5941       1          1     0.997850     True\n",
      "...      ...        ...          ...      ...\n",
      "6837       1          1     0.803543     True\n",
      "5848       0          1     0.752012    False\n",
      "7964       1          1     0.915872     True\n",
      "7628       1          1     0.980007     True\n",
      "6973       1          1     0.978543     True\n",
      "\n",
      "[1572 rows x 4 columns]\n",
      "XGBoost Score:  0.7410941475826972\n"
     ]
    }
   ],
   "source": [
    "# 수치형 전처리\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 범주형 전처리\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 전처리 통합\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# 기본 모델 정의\n",
    "rf = XGBClassifier()\n",
    "\n",
    "# XGBoost 모델 정의\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 파이프라인 구성\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb_model)\n",
    "])\n",
    "\n",
    "# 모델 학습\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "y_proba = model_pipeline.predict_proba(X_test)[:, 1]  # 클래스 1(레드 승) 확률\n",
    "\n",
    "# 결과 DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Probability': y_proba,\n",
    "    'Correct': y_test == y_pred\n",
    "})\n",
    "\n",
    "print(results_df)\n",
    "print('XGBoost Score: ',model_pipeline.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
